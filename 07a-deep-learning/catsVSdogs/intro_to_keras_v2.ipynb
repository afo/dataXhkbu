{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](http://oi64.tinypic.com/o858n4.jpg)\n",
    "\n",
    "\n",
    "# Intro to Deep Learning with Keras\n",
    "\n",
    "#### Author: Alexander Fred Ojala & Ikhlaq Sidhu\n",
    "\n",
    "_____\n",
    "\n",
    "# Why Keras\n",
    "Modular, powerful and intuitive Deep Learning python library built on TensorFlow, CNTK, Theano.\n",
    "* Minimalist, user-friendly interface\n",
    "* CPUs and GPUs\n",
    "* Open-source, developed and maintained by a community of contributors, and\n",
    "publicly hosted on github\n",
    "* Extremely well documented, lots of working examples: https://keras.io/\n",
    "* Very shallow learning curve â€”> it is by far one of the best tools for both beginners and experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level wrappers\n",
    "Compile code down to the deep learning framework (i.e. takes longer to run). See comparison of speed for different DL frameworks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/train_times.png' width=600></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow and Keras warnings for cleaner output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras backend\n",
    "\n",
    "We want Keras to use Tensorflow as a backend. If the warning above does not say:\n",
    "\n",
    "<div class='alert alert-danger'>**Using TensorFlow backend.**</div>\n",
    "\n",
    "Then open up the keras configuration file located in:\n",
    "\n",
    "`$HOME/.keras/keras.json` \n",
    "\n",
    "(On Windows replace `$HOME` with `%USERPROFILE%`)\n",
    "\n",
    "and change the entries in the JSON file to:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"floatx\": \"float32\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"backend\": \"tensorflow\",\n",
    "    \"image_data_format\": \"channels_last\"\n",
    "}\n",
    "```\n",
    "\n",
    "After that restart your Kernel and run the code again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras \"Hello World\" on Iris\n",
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ===================\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR[:980])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode y\n",
    "import pandas as pd\n",
    "\n",
    "y = pd.get_dummies(y).values\n",
    "y[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, test_size=0.4,\n",
    "                                                    random_state=1337,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(90, 3)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sequential model\n",
    "The simplest model in Keras is the Sequential model, a linear stack of layers.\n",
    "\n",
    "* **Sequential model** linear stack of layers: It allows us to build NNs like legos, by adding one layer on top of the other, swapping layers in and out\n",
    "\n",
    "* Graph: multi-input, multi-output, with arbitrary connections inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data structure in Keras is a model\n",
    "# The model is an object in which we organize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential() # instantiate empty Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import layer classes and stack layers (in an NN model for example), by using `.add()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the input shape\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a  Sequential model needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "* Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected).\n",
    "* Some 2D layers, such as Dense, support the specification of their input shape via the argument  input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n",
    "\n",
    "\n",
    "* **The following snippets are strictly equivalent:**\n",
    "* model.add(Dense(32, input_shape=(784,)))\n",
    "* model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model contruction (architecture build computational graph)\n",
    "from keras.layers import Dense\n",
    "\n",
    "model.add( Dense(units=64, activation='relu', input_shape=(4,) ))\n",
    "model.add( Dense(units=3, activation='softmax') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation phase, specify learning process\n",
    "\n",
    "Run `.compile()` on the model to specify learning process.\n",
    "\n",
    "Before training a model, you need to configure the learning process, which is done via the  compile method. It receives three arguments:\n",
    "\n",
    "* **An optimizer:** This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class.\n",
    "* **A loss function:** This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function.\n",
    "* **(Optional) A list of metrics:** For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also specify our own optimizer or loss function\n",
    "\n",
    "```python\n",
    "# or with we can specify loss function\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr=0.001, momentum = 0.9, nesterov=True),\n",
    "             metrics = ['accuracy'])\n",
    "```\n",
    "\n",
    "### Different optimizers and their trade-offs\n",
    "To read more about gradient descent optimizers, hyperparameters etc. This is a recommended reading: http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.5299 - acc: 0.2667\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 0s 112us/step - loss: 1.3058 - acc: 0.2667\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 0s 153us/step - loss: 1.1569 - acc: 0.2667\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 0s 212us/step - loss: 1.0467 - acc: 0.5889\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 0s 390us/step - loss: 0.9817 - acc: 0.6111\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 0s 428us/step - loss: 0.9397 - acc: 0.3778\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 0s 374us/step - loss: 0.9124 - acc: 0.1333\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 0s 348us/step - loss: 0.8917 - acc: 0.1556\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 0s 403us/step - loss: 0.8729 - acc: 0.2889\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 0s 459us/step - loss: 0.8566 - acc: 0.4667\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 0s 301us/step - loss: 0.8397 - acc: 0.5667\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 0s 377us/step - loss: 0.8239 - acc: 0.6000\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 0s 367us/step - loss: 0.8064 - acc: 0.6222\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 0s 283us/step - loss: 0.7921 - acc: 0.6556\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 0s 391us/step - loss: 0.7722 - acc: 0.6667\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 0s 152us/step - loss: 0.7576 - acc: 0.7778\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 0s 136us/step - loss: 0.7442 - acc: 0.8111\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 0s 149us/step - loss: 0.7323 - acc: 0.8222\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 0s 792us/step - loss: 0.7205 - acc: 0.8556\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 0s 768us/step - loss: 0.7099 - acc: 0.8222\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 0s 528us/step - loss: 0.6992 - acc: 0.8111\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 0s 326us/step - loss: 0.6878 - acc: 0.7889\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 0s 127us/step - loss: 0.6771 - acc: 0.8000\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 0s 371us/step - loss: 0.6672 - acc: 0.8333\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 0s 485us/step - loss: 0.6576 - acc: 0.8444\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 0s 648us/step - loss: 0.6493 - acc: 0.8667\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 0s 376us/step - loss: 0.6399 - acc: 0.8667\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 0s 271us/step - loss: 0.6314 - acc: 0.9111\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 0s 261us/step - loss: 0.6242 - acc: 0.9556\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.6163 - acc: 0.9667\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 0s 328us/step - loss: 0.6087 - acc: 0.9667\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 0s 719us/step - loss: 0.6014 - acc: 0.9556\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 0s 554us/step - loss: 0.5942 - acc: 0.9444\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 0s 353us/step - loss: 0.5876 - acc: 0.9333\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 0s 440us/step - loss: 0.5816 - acc: 0.9111\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 0s 447us/step - loss: 0.5737 - acc: 0.9000\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 0s 486us/step - loss: 0.5688 - acc: 0.9444\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 0s 639us/step - loss: 0.5614 - acc: 0.9556\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 0s 606us/step - loss: 0.5538 - acc: 0.9556\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 0s 692us/step - loss: 0.5473 - acc: 0.9556\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 0s 873us/step - loss: 0.5415 - acc: 0.9333\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 0s 624us/step - loss: 0.5357 - acc: 0.9333\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5304 - acc: 0.9222\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5243 - acc: 0.9222\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 0s 453us/step - loss: 0.5202 - acc: 0.9444\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 0s 412us/step - loss: 0.5130 - acc: 0.9667\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 0s 504us/step - loss: 0.5080 - acc: 0.9667\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 0s 854us/step - loss: 0.5032 - acc: 0.9667\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 0s 662us/step - loss: 0.4978 - acc: 0.9667\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4926 - acc: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f743c0afd30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666388511658"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Evaluate the model Accuracy on test set\n",
    "model.evaluate(X_test, y_test, batch_size=60,verbose=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on new data:\n",
    "\n",
    "class_probabilities = model.predict(X_test, batch_size=128)\n",
    "\n",
    "# gives output of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08671617, 0.50276315, 0.41052073],\n",
       "       [0.8398964 , 0.11209006, 0.04801363],\n",
       "       [0.0219885 , 0.40420935, 0.5738022 ],\n",
       "       [0.77496237, 0.15529333, 0.06974428],\n",
       "       [0.01476524, 0.37532917, 0.60990566]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras DNN on MNIST\n",
    "\n",
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_dim = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_dim)\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model to stack layers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model constructor\n",
    "model = Sequential()\n",
    "# Add layers sequentially\n",
    "model.add(Dense(300, activation=tf.nn.leaky_relu, input_shape=(784,) ) )\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Second..\n",
    "model.add(Dense(200, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Third..\n",
    "model.add(Dense(100, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 316,810\n",
      "Trainable params: 316,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='adam', #chooses suitable learning rate for you.\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.3039 - acc: 0.9087\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.1297 - acc: 0.9604\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0983 - acc: 0.9697\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 20s 332us/step - loss: 0.0797 - acc: 0.9752\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=4, batch_size=128,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08236757314146961\n",
      "Test accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(4),history.history['acc'])\n",
    "plt.title('accuracy per iteration')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great accuracy for an ANN in so few training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in Keras\n",
    "## 99.5% accuracy on MNIST in 12 epochs\n",
    "\n",
    "Note this takes ~1hr to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# notice that we don't flatten image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost LeNet architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
